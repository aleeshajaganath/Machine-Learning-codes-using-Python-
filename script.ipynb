{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "dda4fc99-2f89-e2aa-aeb4-f702cc51afaa"
      },
      "outputs": [],
      "source": [
        "# This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
        "# For example, here's several helpful packages to load in \n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "# Input data files are available in the \"../input/\" directory.\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
        "\n",
        "from subprocess import check_output\n",
        "print(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n",
        "\n",
        "# Any results you write to the current directory are saved as output."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "ea5ca33e-fdfc-e060-aade-bcda984694d0"
      },
      "outputs": [],
      "source": [
        "DATA_FILE = '../input/spam.csv'\n",
        "df = pd.read_csv(DATA_FILE,encoding='latin-1')\n",
        "print(df.head())\n",
        "\n",
        "tags = df.v1\n",
        "texts = df.v2\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation\n",
        "from keras.layers import Embedding\n",
        "from keras.layers import Conv1D, GlobalMaxPooling1D\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing import sequence\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import time\n",
        "from keras import metrics\n",
        "print('import done')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "a6bf4566-ed56-7d41-f46c-e9b92c788bcc"
      },
      "outputs": [],
      "source": [
        "num_max = 1000\n",
        "# preprocess\n",
        "le = LabelEncoder()\n",
        "tags = le.fit_transform(tags)\n",
        "tok = Tokenizer(num_words=num_max)\n",
        "tok.fit_on_texts(texts)\n",
        "mat_texts = tok.texts_to_matrix(texts,mode='count')\n",
        "print(tags[:5])\n",
        "print(mat_texts[:5])\n",
        "print(tags.shape,mat_texts.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "37a8025b-eeac-f70f-1768-a7d66dc7c210"
      },
      "outputs": [],
      "source": [
        "# try a simple model first\n",
        "\n",
        "def get_simple_model():\n",
        "    model = Sequential()\n",
        "    model.add(Dense(512, activation='relu', input_shape=(num_max,)))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(Dense(256, activation='relu'))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "    model.summary()\n",
        "    model.compile(loss='binary_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['acc',metrics.binary_accuracy])\n",
        "    print('compile done')\n",
        "    return model\n",
        "\n",
        "def check_model(model,x,y):\n",
        "    model.fit(x,y,batch_size=32,epochs=10,verbose=1,validation_split=0.2)\n",
        "\n",
        "m = get_simple_model()\n",
        "check_model(m,mat_texts,tags)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "4f3ff2b6-ed23-076a-141d-25adbc4f8592"
      },
      "outputs": [],
      "source": [
        "# for cnn preproces\n",
        "max_len = 100\n",
        "cnn_texts_seq = tok.texts_to_sequences(texts)\n",
        "print(cnn_texts_seq[0])\n",
        "cnn_texts_mat = sequence.pad_sequences(cnn_texts_seq,maxlen=max_len)\n",
        "print(cnn_texts_mat[0])\n",
        "print(cnn_texts_mat.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "e06c4200-569d-d9b0-b36c-8a8534157f01"
      },
      "outputs": [],
      "source": [
        "def get_cnn_model_v1():   \n",
        "    model = Sequential()\n",
        "    # we start off with an efficient embedding layer which maps\n",
        "    # our vocab indices into embedding_dims dimensions\n",
        "    # 1000 is num_max\n",
        "    model.add(Embedding(1000,\n",
        "                        20,\n",
        "                        input_length=max_len))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(Conv1D(64,\n",
        "                     3,\n",
        "                     padding='valid',\n",
        "                     activation='relu',\n",
        "                     strides=1))\n",
        "    model.add(GlobalMaxPooling1D())\n",
        "    model.add(Dense(256))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(Dense(1))\n",
        "    model.add(Activation('sigmoid'))\n",
        "    model.summary()\n",
        "    model.compile(loss='binary_crossentropy',\n",
        "                  optimizer='adam',\n",
        "                  metrics=['acc',metrics.binary_accuracy])\n",
        "    return model\n",
        "\n",
        "m = get_cnn_model_v1()\n",
        "check_model(m,cnn_texts_mat,tags)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "6578767b-e047-1b6d-c128-3e2e4e3e2414"
      },
      "outputs": [],
      "source": [
        "def get_cnn_model_v2(): # added embed   \n",
        "    model = Sequential()\n",
        "    # we start off with an efficient embedding layer which maps\n",
        "    # our vocab indices into embedding_dims dimensions\n",
        "    # 1000 is num_max\n",
        "    model.add(Embedding(1000,\n",
        "                        50, #!!!!!!!!!!!!!!!!!!!!!!!\n",
        "                        input_length=max_len))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(Conv1D(64,\n",
        "                     3,\n",
        "                     padding='valid',\n",
        "                     activation='relu',\n",
        "                     strides=1))\n",
        "    model.add(GlobalMaxPooling1D())\n",
        "    model.add(Dense(256))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(Dense(1))\n",
        "    model.add(Activation('sigmoid'))\n",
        "    model.summary()\n",
        "    model.compile(loss='binary_crossentropy',\n",
        "                  optimizer='adam',\n",
        "                  metrics=['acc',metrics.binary_accuracy])\n",
        "    return model\n",
        "\n",
        "m = get_cnn_model_v2()\n",
        "check_model(m,cnn_texts_mat,tags)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "d1a65f27-c61e-13db-49ff-7cf816b70fa1"
      },
      "outputs": [],
      "source": [
        "def get_cnn_model_v3():    # added filter\n",
        "    model = Sequential()\n",
        "    # we start off with an efficient embedding layer which maps\n",
        "    # our vocab indices into embedding_dims dimensions\n",
        "    # 1000 is num_max\n",
        "    model.add(Embedding(1000,\n",
        "                        20,\n",
        "                        input_length=max_len))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(Conv1D(256, #!!!!!!!!!!!!!!!!!!!\n",
        "                     3,\n",
        "                     padding='valid',\n",
        "                     activation='relu',\n",
        "                     strides=1))\n",
        "    model.add(GlobalMaxPooling1D())\n",
        "    model.add(Dense(256))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(Dense(1))\n",
        "    model.add(Activation('sigmoid'))\n",
        "    model.summary()\n",
        "    model.compile(loss='binary_crossentropy',\n",
        "                  optimizer='adam',\n",
        "                  metrics=['acc',metrics.binary_accuracy])\n",
        "    return model\n",
        "\n",
        "m = get_cnn_model_v3()\n",
        "check_model(m,cnn_texts_mat,tags)"
      ]
    }
  ],
  "metadata": {
    "_change_revision": 0,
    "_is_fork": false,
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}